---
title: "Adjoint of a linear operator"
layout: example
authordate: "Yuji Nakatsukasa, February 2017"
meta: "(Chebfun example ode-linear/adjoints.m)"
---



## 1. Adjoint of a chebop

Let $L$ be a linear operator on the Hilbert space $H=L_2[-1,1]$ together with homogeneous boundary conditions. The adjoint of $L^\ast$ is defined as another operator, together with another set of homogeneous boundary conditions, such that $$(v,Lu)= (L^\ast v,u) $$ for all $u,v\in H$ such that $u$ satisfies the boundary condition of $L$ and $y$ satisfies the boundary condition of $L^\ast$. As of version 5.6.0, Chebfun is able to compute the adjoint of a linear operator represented as a chebop by the command `adjoint`. The operator adjoint is a classical subject [3], and the mathematical background for Chebfun's `adjoint` is summarized in [2]. The programming was done by Jared Aurentz, and much of this example is taken from a talk by him at a seminar in 2016 at Oxford.

For example, here is the adjoint of the first derivative operator with a Dirichlet boundary condition at the left boundary.

<pre class="mcode-input">L = chebop([-1 1]);
L.op = @(u) diff(u);
L.lbc = @(u) u
Ls = adjoint(L)</pre><pre class="mcode-output">L =
   Linear operator:
      u |--&gt; diff(u)
   operating on chebfun objects defined on:
      [-1,1]
   with
    left boundary condition(s):
      u = 0
Ls =
   Linear operator:
      v |--&gt; -diff(v)
   operating on chebfun objects defined on:
      [-1,1]
   with
    right boundary condition(s):
      v = 0
</pre>Note the sign change in the operator, which comes from integration by parts. Note also the change in the boundary condition, which has switched from an initial condition $u(-1)=0$ to a final condition $v(1)=0$. Let's check that the adjoint condition is satisfied:

<pre class="mcode-input">x = chebfun('x');
u = (x+1).*sin(x);            % function with u(-1) = 0
v = (x-1).*exp(x);            % function with v(1) = 0
abs(v'*(L*u) - (Ls*v)'*u)</pre><pre class="mcode-output">ans =
     0
</pre>For self-adjoint operators with self-adjoint boundary conditions, the adjoint is itself:

<pre class="mcode-input">L = chebop([-1 1]);
L.op = @(u) diff(u,2)+u; % u''
L.lbc = @(u) u; L.rbc = @(u) u
Ls = adjoint(L)</pre><pre class="mcode-output">L =
   Linear operator:
      u |--&gt; diff(u,2)+u
   operating on chebfun objects defined on:
      [-1,1]
   with
    left boundary condition(s):
      u = 0
    right boundary condition(s):
      u = 0
Ls =
   Linear operator:
      v |--&gt; diff(v,2)+v
   operating on chebfun objects defined on:
      [-1,1]
   with
    left boundary condition(s):
      v = 0
    right boundary condition(s):
      v = 0
</pre>

## 2. Adjoint boundary conditions

With the same operator, if we change the boundary conditions so that we have an initial value problem, the problem is no longer self-adjoint and the adjoint becomes a final value problem (as we saw above). The adjoint operator is still the formal adjoint $L^\ast v=v''+v$.

<pre class="mcode-input">L = chebop([-1 1]);
L.op = @(u) diff(u,2)+u;
L.lbc = @(u) [ u-1; diff(u) ]  % initial value problem with both BCs at left end
Ls = adjoint(L)</pre><pre class="mcode-output">L =
   Linear operator:
      u |--&gt; diff(u,2)+u
   operating on chebfun objects defined on:
      [-1,1]
   with
    left boundary condition(s):
      [u-1;diff(u)] = 0
Ls =
   Linear operator:
      v |--&gt; diff(v,2)+v
   operating on chebfun objects defined on:
      [-1,1]
   with
    right boundary condition(s):
      [v;diff(v)] = 0
</pre>If there's only one (more generally $k$) boundary condition in $L$, then the adjoint will have $2d-1=3$ (or $2d-k$) boundary conditions, where $d$ is the order of the differential operator (here 2).

<pre class="mcode-input">L.lbc = @(u) u-1;  % just one BC
Ls = adjoint(L)</pre><pre class="mcode-output">Ls =
   Linear operator:
      v |--&gt; diff(v,2)+v
   operating on chebfun objects defined on:
      [-1,1]
   with
    left boundary condition(s):
      v = 0
    right boundary condition(s):
      [v;diff(v)] = 0
</pre>The boundary conditions of the original and adjoint operators are related in an intricate manner, with those of the adjoint satisfying a null vector condition involving a so-called complementarity matrix. For details, see [2,3].

Let's try an operator with variable coefficients.

<pre class="mcode-input">L = chebop([-1 1]);
L.op = @(x,u) x.*diff(u,2);
L.lbc = @(u) u; L.rbc = @(u) u
Ls = adjoint(L)</pre><pre class="mcode-output">L =
   Linear operator:
      u |--&gt; x.*diff(u,2)
   operating on chebfun objects defined on:
      [-1,1]
   with
    left boundary condition(s):
      u = 0
    right boundary condition(s):
      u = 0
Ls =
   Linear operator:
      v |--&gt; a11_2.*diff(v,2)+a11_1.*diff(v)
   operating on chebfun objects defined on:
      [-1,1]
   with
    left boundary condition(s):
      v = 0
    right boundary condition(s):
      v = 0
</pre>The formal adjoint here is $L^\ast v = (xv)''$. Note that the Chebfun display of $L^\ast$ is not very informative, as one can't see what the variable coefficients are.  This happens because Chebfun is a numerical system, not symbolic: its representation of each coefficient function is not an algebraic expression but a Chebyshev series that aims for the usual 16-digit accuracy.

Let's check that the adjoint equation is satisfied.

<pre class="mcode-input">x = chebfun('x');
u = (x.^2-1).*sin(x);
v = (x.^2-1).*exp(x);
abs(v'*(L*u) - (Ls*v)'*u)</pre><pre class="mcode-output">ans =
     4.440892098500626e-16
</pre>

## 3. Eigenvalues and eigenfunctions of the adjoint

The eigenvalues of an operator and its adjoint are complex conjugates of each other, so if the eigenvalues are real, then they are the same for $L$ and $L^\ast$.  Let's verify this a with non-self-adjoint example, an advection-diffusion operator.

<pre class="mcode-input">L = chebop([-1 1]);
L.op = @(x,u) diff(u,2) -20*diff(u) + u;
L.lbc = @(u) u; L.rbc = @(u) u;
Ls = adjoint(L);

[V,D] = eigs(L);
[Vs,Ds] = eigs(Ls);

[diag(D) diag(Ds)]</pre><pre class="mcode-output">ans =
   1.0e+02 *
  -1.878264592127668  -1.878264527916655
  -1.606850187218044  -1.606850191907498
  -1.384784202819554  -1.384784215633707
  -1.212066098841079  -1.212066087515042
  -1.088696038777262  -1.088696044206861
  -1.014674013146135  -1.014674011880154
</pre>Since if $Lx=\lambda x$ and $L^\ast y=\bar{\mu} y$ then $(y,Lx) = \bar{\lambda}(y,x)$ and $(L^\ast y,x) =\mu(y,x)$, it follows that if $\lambda\neq \mu$, then $(y,x)=0$, i.e., left and right eigenfunctions are orthogonal. We can confirm this as follows:

<pre class="mcode-input">Vs'*V</pre><pre class="mcode-output">ans =
   1.0e-05 *
  Columns 1 through 3
   0.017526318950153  -0.000000004632513   0.000000003257778
   0.000000000462302   0.021610288998378  -0.000000002353983
   0.000000002364841   0.000000003859690   0.029128457246412
  -0.000000002988200  -0.000000004094531   0.000000006284440
  -0.000000003279067  -0.000000004185653   0.000000005417629
   0.000000003401038   0.000000004208956  -0.000000005160911
  Columns 4 through 6
   0.000000003062796  -0.000000003106372  -0.000000003145685
  -0.000000002557211   0.000000002806218   0.000000002939766
  -0.000000000936118   0.000000002138338   0.000000002538706
   0.045371472569969   0.000000000185506  -0.000000001515532
   0.000000008147055   0.091780019385484   0.000000002195240
  -0.000000006563901   0.000000010523851   0.342386231509402
</pre>Let's plot the first two eigenfunctions of $L$ and of $L^\ast$. Note that the curves are symmetric about the origin.

<pre class="mcode-input">LW = 'linewidth'; CO = 'color'; FS = 'fontsize';
for ii = 1:2
    v = V{ii}; if v(.9) &lt; 0, v = -v; end
    plot(v,'r'), hold on
    vs = Vs{ii}; if vs(-.9) &lt; 0, vs = -vs; end
    plot(vs,'b')
end
text(-.8,2,'adjoint eigenfunctions',CO,'b',FS,14)
text(.3,2,'eigenfunctions',CO,'r',FS,14)
shg</pre><img src="img/Adjoints_01.png" class="figure" alt="">

The first eigenfunction is very far from orthogonal to the second -- in fact, they are nearly the same:

<pre class="mcode-input">V(:,2)'*V(:,1)</pre><pre class="mcode-output">ans =
   0.994385163800641
</pre>There is a lot of physics in a figure like this; see chapter 12 of [1].    The concentration of the eigenfunctions at the right boundary reflects the fact that this operator governs rightward propagation, and solutions tend to "pile up" at the right boundary before eventually being absorbed by the diffusion.  The concentration of the adjoint eigenfunctions at the left boundary reflects that fact that if you want to control a solution, the most effective place to insert a signal is at the left.



## References

1. M. Embree and L. N. Trefethen, _Spectra and Pseudospectra: The Behavior of Nonnormal Matrices and Operators_, Princeton U. Press, 2005.

2. Hrothgar, _Block Operators and Continuous Adjoint Methods_, transfer thesis, Dept. of Mathematics, U. of Oxford, 2015.

3. I. Stakgold and M. J. Holst. _Green's Functions and Boundary Value Problems_. John Wiley &amp; Sons, 2011.

