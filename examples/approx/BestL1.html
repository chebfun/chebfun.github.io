<!DOCTYPE html>
<html>
  <head>
    <title>Best polynomial approximation in the L^1 norm &raquo; Chebfun</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta charset="utf-8">
    <link rel="shortcut icon" href="favicon.ico" />

    <!-- Bootstrap -->
    <link href="/css/bootstrap.min.css" rel="stylesheet"><!--  media="screen" -->
    <link href="/css/normalize.min.css" rel="stylesheet"><!--  media="screen" -->
    <link href="/css/chebsite.css" rel="stylesheet"><!--  media="screen" -->
    <link href="/css/tomorrow.css" rel="stylesheet"><!--  media="screen" -->
    <link href="/css/flexslider.css" rel="stylesheet"><!--  media="screen" -->

    <link href='https://fonts.googleapis.com/css?family=Ubuntu+Mono:400,700,400italic' rel='stylesheet' type='text/css'>
    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
      <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
    <![endif]-->
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-LRD09XBKHN"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-LRD09XBKHN');
</script>  </head>
  <body>
    <!-- Fixed navbar -->
    <div id='navbar' class="navbar navbar-default navbar-fixed-top">
      <div class="container nav">
        <div class="navbar-header">
          <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse"><span class="icon-bar"></span><span class="icon-bar"></span><span class="icon-bar"></span></button>
          <a id="logo" href="/"><img src='/images/logo.png' /></a>
        </div>
        <div class="navbar-collapse collapse">
          <ul class="nav navbar-nav navbar-right">
            <li><a href="/about">About</a></li>
            <li><a href="/news">News</a></li>
            <li><a href="/download">Download</a></li>
            <li><a href="/docs">Docs</a></li>
            <li><a href="/examples">Examples</a></li>
            <li><a href="/support">Support</a></li>
            <li><a href="/search"><span class="glyphicon glyphicon-search"></span></a></li>
            <li><a href="https://github.com/chebfun/chebfun"><img id='github-logo' src='/css/github-logo.png'/></a></li>
          </ul>
        </div><!--/.nav-collapse -->
      </div>
    </div>
<div class="page-wrapper">

    <div class='page-header'>
<h1>Best polynomial approximation in the L^1 norm</h1>
<h2>Yuji Nakatsukasa and Alex Townsend, July 2019 in <a href='/examples/approx/'>approx</a><span><a href='/examples/approx/BestL1.m'>download</a><span class='sep-sm'>&middot;</span><a href='//github.com/chebfun/examples/blob/master/approx/BestL1.m'>view on GitHub</a></span></h2>
</div>

    <div class="container">
<div class="row main">
<div id='content' class="col-sm-12 example" role="main">
<h3 id="polynomial-approximation-in-the-linfty-norm">Polynomial approximation in the $L^\infty$ norm</h3>
<p>Given a continuous real-valued function $f$ on $[a,b]$, finding the best polynomial approximant $p_\infty$ to $f$ in the $L^\infty$-norm $\mbox{min}_{p\in\mathcal{P}_n}|f-p|_{L^{\infty}}$ is known as the minimax (or sometimes Chebyshev) approximation problem. These approximations can be computed by the Chebfun <code>minimax</code> command. Let's revisit the Chebfun example <a href="https://www.chebfun.org/examples/approx/ResolutionWiggly.html">https://www.chebfun.org/examples/approx/ResolutionWiggly.html</a> and compute a best polynomial approximant of degree 100:</p>
<pre class="mcode-input">dom = [0 14]; deg = 100;
f = chebfun(@(x) sin(x)^2 + sin(x^2), dom);
pinf = minimax(f, deg, 'tol', 1e-8);
plot([f pinf]), ylim([-3 3]), grid on
title('f and Linfty approximant')</pre>

<p><img src="img/BestL1_01.png" class="figure" alt=""></p>
<p>The error $f-p_\infty$ exhibits the beautiful equioscillation phenomenon:</p>
<pre class="mcode-input">plot(f-pinf,'k'), ylim([-3 3]), grid on
title('error of Linfty approximant')</pre>

<p><img src="img/BestL1_02.png" class="figure" alt=""></p>
<h3 id="polynomial-approximation-in-the-l2-norm">Polynomial approximation in the $L^2$ norm</h3>
<p>The best polynomial approximant to $f$ in the $L^2$-norm is easier to compute as it is the orthogonal projection of $f$ onto the space of polynomials of degree $n$. In Chebfun, one can use the <code>polyfit</code> command:</p>
<pre class="mcode-input">p2 = polyfit(f, deg);
plot([f p2]), ylim([-3 3]), grid on
title('f and L2 approximant')</pre>

<p><img src="img/BestL1_03.png" class="figure" alt=""></p>
<p>The error curve is strikingly different.  Of course it is slightly larger at its largest, but not by much.</p>
<pre class="mcode-input">plot(f-p2,'k'), ylim([-3 3]), grid on
title('error of L2 approximant')</pre>

<p><img src="img/BestL1_04.png" class="figure" alt=""></p>
<h3 id="polynomial-approximation-in-the-l1-norm">Polynomial approximation in the $L^1$ norm</h3>
<p>Recently, we added a Chebfun <code>polyfitL1</code> command to compute best polynomial approximants in the $L^1$-norm. (See the book by Pinkus for a survey of this subject [2].)  Compressed sensing has made the $L^1$ norm an important tool in signal processing as it can promote sparsity in the solution or residual. A Newton-based algorithm proposed by Watson [4] is known to converge, under some assumptions, and this is the basis of <code>polyfitL1</code>.</p>
<pre class="mcode-input">p1 = polyfitL1(f, deg);
plot([f p1]), ylim([-3 3]), grid on
title('f and L1 approximant')</pre>

<p><img src="img/BestL1_05.png" class="figure" alt=""></p>
<p>Here is the error curve for our example. At first glance it looks like the $L^2$ case, but it is more strongly localized.</p>
<pre class="mcode-input">plot(f-p1,'k'), ylim([-3 3]), grid on
title('error of L1 approximant')</pre>

<p><img src="img/BestL1_06.png" class="figure" alt=""></p>
<h3 id="another-example">Another example</h3>
<p>Let's do another example, following the example of Myth 3 of [3], the approximation of $|x-1/4|$ on $[-1,1]$ by a polynomial of degree $80$. This time we just plot the errors:</p>
<pre class="mcode-input">x = chebfun('x'); f = abs(x-1/4);
deg = 80;
pinf = minimax(f, deg);
plot(f-pinf,'k'), ylim(1e-2*[-1 1]), grid on
title('Linf error'), snapnow
p2 = polyfit(f, deg);
plot(f-p2,'k'), ylim(1e-2*[-1 1]), grid on
title('L2 error'), snapnow
p1 = polyfitL1(f, deg);
plot(f-p1,'k'), ylim(1e-2*[-1 1]), grid on
title('L1 error')</pre>

<p><img src="img/BestL1_07.png" class="figure" alt=""></p>
<p><img src="img/BestL1_08.png" class="figure" alt=""></p>
<p><img src="img/BestL1_09.png" class="figure" alt=""></p>
<p>Again, we see that the best $L^1$ polynomial approximant has a far more localized error. This is a typical phenomenon that is explained in~[1].  To see more, we zoom the y axis by a factor of 100.  There is much to be learned here!</p>
<pre class="mcode-input">ylim(1e-4*[-1 1])
title('closeup')</pre>

<p><img src="img/BestL1_10.png" class="figure" alt=""></p>
<h3 id="a-word-on-the-algorithm-for-polyfitl1">A word on the algorithm for <code>polyfitL1</code></h3>
<p>In [1], it is recommended that Watson's algorithm should be used in conjunction with linear programming problems and a refinement step. These additional algorithmic details can significantly speed up the computation. However, MATLAB's linear programming commands are in a toolbox, so we have avoided these steps in keeping with the Chebfun policy of just relying on core MATLAB.</p>
<h3 id="references">References</h3>
<p>[1] Y. Nakatsukasa and A. Townsend, Error localization of best L1 polynomial approximants, SIAM J. Numer. Anal., 59 (2021), 314--333.</p>
<p>[2] A. M. Pinkus, <em>On L1-approximation</em>, Cambridge University Press, 1989.</p>
<p>[3] L. N. Trefethen, Six myths of polynomial interpolation and quadrature, appendix of <em>Approximation Theory and Approximation Practice, extended edition</em>, SIAM, 2019.</p>
<p>[4] G. A. Watson. An algorithm for linear L1 approximation of continuous functions, <em>IMA J. Numer. Anal.</em>, 1 (1981), 157--167.</p></div>
        </div>
    </div>
</div>
    <div class="footer">
        <p>&copy; Copyright 2025 the University of Oxford and the Chebfun Developers.</p>
    </div>

    <!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
    <script type="text/javascript" src="https://code.jquery.com/jquery-1.7.2.min.js"></script>
    <!-- Include all compiled plugins (below), or include individual files as needed -->
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script src="/js/bootstrap.min.js"></script>
    <script src="https://cdn.rawgit.com/google/code-prettify/master/loader/run_prettify.js?lang=matlab" type="text/javascript"></script>
    <script type="text/javascript" src="/js/config.js"></script>
    <script type="text/javascript" src="/js/jquery.flexslider-min.js"></script>
  </body>
</html>